---
title: '1990s vs 2010s: How has Hip-Hop changed?'
author: "Noa Nonkes"
date: "February - March 2022"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    theme: yeti
    self_contained: false
---

```{r setup, include=FALSE}
library(flexdashboard)
library(compmus)
library(spotifyr)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(ggpubr)
library(plotly)

tracks90 <- get_playlist_tracks("37i9dQZF1DX186v583rmzp")
features90 <- get_track_audio_features(tracks90$track.id)

tracks10 <- get_playlist_tracks("37i9dQZF1DWSMW5YBCZisa")
features10 <- get_track_audio_features(tracks10$track.id)

tracks15 <- get_playlist_tracks("37i9dQZF1DXcqWbpeXswkc")
features15 <- get_track_audio_features(tracks15$track.id)

features10$year <- as.character(2010)
features15$year <- as.character(2010)
features90$year <- as.character(1990)

tracks10 <- tracks10 %>% mutate(artists.name = map_chr(track.album.artists, function(x) x$name[1]))
tracks15 <- tracks15 %>% mutate(artists.name = map_chr(track.album.artists, function(x) x$name[1]))
tracks90 <- tracks90 %>% mutate(artists.name = map_chr(track.album.artists, function(x) x$name[1]))

features10$artists.name <- tracks10$artists.name
features90$artists.name <- tracks90$artists.name
features15$artists.name <- tracks15$artists.name

features10$track.name <- tracks10$track.name
features90$track.name <- tracks90$track.name
features15$track.name <- tracks15$track.name

features <- rbind(rbind(features90, features10), features15)
```

### Track-Level Summaries
```{r}
hiphop90 <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "37i9dQZF1DX186v583rmzp"
  ) %>%
  add_audio_analysis()
hiphop10 <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "37i9dQZF1DWSMW5YBCZisa"
  ) %>%
  add_audio_analysis()
hiphop15 <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "37i9dQZF1DXcqWbpeXswkc"
  ) %>%
  add_audio_analysis()
hiphopfeatures <- 
  hiphop90 %>%
  mutate(year = "1990") %>%
  bind_rows(hiphop10 %>% mutate(year = "2010")) %>%
  bind_rows(hiphop15 %>% mutate(year = "2010"))

hiphopfeatures %>%
  mutate(
    timbre =
      map(
        segments,
        compmus_summarise,
        timbre,
        method = "mean"
      )
  ) %>%
  select(year, timbre) %>%
  compmus_gather_timbre() %>%
  ggplot(aes(x = basis, y = value, fill = year)) +
  geom_violin() +
  scale_fill_viridis_d() +
  labs(x = "Spotify Timbre Coefficients", y = "", fill = "Year")
```

### Cepstrograms  

```{r}
icecube <-
  get_tidy_audio_analysis("67ncYmW29pNJJY2yXuLPwT") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

icecubePlot <- icecube %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "You Know How We Do It by Ice Cube") +
  scale_fill_viridis_c() + 
  theme_classic() +
  theme(plot.title = element_text(size=12, hjust = 0.5))

kidcudi <-
  get_tidy_audio_analysis("393MDhe62s8hbH8ETrlxe5") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

kidcudiPlot <- kidcudi %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Mr. Rager by Kid Cudi") +
  scale_fill_viridis_c() +
  theme_classic() +
  theme(plot.title = element_text(size=12, hjust = 0.5))

figure <- ggarrange(icecubePlot, kidcudiPlot, ncol = 2, nrow = 1, common.legend = TRUE)

figure
```

***
<iframe src="https://open.spotify.com/embed/track/393MDhe62s8hbH8ETrlxe5?theme=0" width="100%" height="80" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>
<iframe src="https://open.spotify.com/embed/track/67ncYmW29pNJJY2yXuLPwT?theme=0" width="100%" height="80" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

In this plot I show two songs with the lowest speechiness in my corpus. On the left I have You Know How We Do It by Ice Cube and on the right I have Mr. Rager by Kid Cudi. 

The left shows a quite constant presence of the c01 coefficient. Only the begin and end have a lower magnitude, as the song fades in and out. The constant presence of c01 can possibly be explained by the fact that the song has a constant beat with no choruses or verses. 

This is different in the right plot as the magnitude of c01 and c02 coefficients seem to alternate each other. These alternations exactly match the chorus and verse in the song. The c02 coefficient represents brightness, so the verses seem to have a higher brightness than the choruses. 

At about 200 seconds in the right plot, it shows a high magnitude in the c02. This may be caused by the fact the singer starts singer higher and longer notes. 

Both songs seem to have a constant presence of the c06 coefficient. 

### Self similarity matrices 
```{r}
asaprocky <-
  get_tidy_audio_analysis("1j6kDJttn6wbVyMaM42Nxm") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

asaprockyTimbrePlot <- asaprocky %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Timbre") +
  theme(plot.title = element_text(size=12, hjust = 0.5))

asaprockyChromaPlot <- asaprocky %>%
  compmus_self_similarity(pitches, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Chroma") +
  theme(plot.title = element_text(size=12, hjust = 0.5))

figure <- ggarrange(asaprockyTimbrePlot, asaprockyChromaPlot, ncol = 2, nrow = 1, common.legend = TRUE)

figure
```

***
<iframe src="https://open.spotify.com/embed/track/1j6kDJttn6wbVyMaM42Nxm?theme=0" width="100%" height="80" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

Here I show a self-similarity matrix of the song with the highest tempo in my corpus: Lord Pretty Flacko Jodye 2 (LPFJ2) by A$AP Rocky. This song has a BPM of 207.982, it however feels more like 104 BPM. 

In both matrices a dark blue diagonal is visible, so the moments in the song are highly similar here. This makes sense, because here the song is compared with the exact same moment in time. 

Also, in both timbre and chroma a low similarity band is seen along the x- and y-axis. This is caused by the fact the song has a constant four note melody playing, except in the beginning of the song. 

The whole feel of the song is quite the same, which is why so much of the timbre matrix shows that the song is very similar to itself. However, little differences in rap melody or in the constant background melody become very visible in the chroma matrix. These are represented by the horizontal and vertical green lines. At about 85 seconds, the background track fades away for a small amount of time (which is a big change in feel), which also can be seen in the timbre matrix by the green horizontal and vertical line at this time stamp. 

### **Introduction:** The shift of Hip-Hop {data-commentary-width=600}
**Chosen Corpus**
I will be using three Spotify playlists, namely ["Best Rap Songs of 2010"](https://open.spotify.com/playlist/37i9dQZF1DX38t16fuNXJJ?si=4f83c993c8904728), ["Best Rap Songs of 2015"](https://open.spotify.com/playlist/37i9dQZF1DXcqWbpeXswkc?si=7246210a99d641d7) and ["I Love My '90s Hip-Hop"](https://open.spotify.com/playlist/37i9dQZF1DX186v583rmzp?si=9ea41443c20e40f1). They respectively have fifty, fifty, and a hundred songs in them. I chose this corpus, since I am a big fan of '90s Hip-Hop and I am curious how the Hip-Hop genre has changed in the next two decades. The two playlists from the '10s will represent this decade together. The research question I will try to answer in this storyboard is: What are the measurable differences between 1990's and 2010's Hip-Hop?

**Characteristics of the Corpus**
Both playlists consist of various artists and albums. They only have the genre in common: Hip-Hop. I expect Hip-Hop songs from the '90s to be more alike, as they often use samples or jazz influences in their songs. I also expect Hip-Hop songs from the 2010's to have a higher danceability, as the Hip-Hop genre became more widely made, so that it may have gotten more pop influences. 
The '90s playlist has tracks from 1990 up until 1999, the '10s playlists have a less equally distributed year range. Fifty tracks are from 2010 and the other fifty tracks are from 2015. 

**Representativeness of the Corpus**
All playlists consist of a broad range of different artists from their decade, but also some songs of the same artists. This could be a limitation of the corpus. 

**Typical and Atypical Tracks**
A typical track from the '90s playlist is [Do for Love by 2Pac](https://open.spotify.com/track/4AE7Lj39VnSZNOmGH2iZaq?si=d1ee18d3341a4cee). It uses a sample and from the '70s and has very meaningful lyrics. An atypical track from the '90s playlist is [Insane in the Brain by Cypress Hill](https://open.spotify.com/track/1oTHteQbmJw15rPxPVXUTv?si=330f37b1dad84b14), as it has a very different vibe as opposed to the other songs in the playlist.

-- want to add (a)typical tracks from 2010's playlist here --

***


<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DWSMW5YBCZisa?theme=0" width="50%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DXcqWbpeXswkc?theme=0" width="50%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DX186v583rmzp?theme=0" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

### Is there need for an increased tempo in Hip-Hop music? {data-commentary-width=400}

```{r}
features_selected <- features %>% select(tempo, year)

meanTempo <- features_selected %>% group_by(year) %>% summarize(mean.tempo = mean(tempo))

tempoPlot <- ggplot(features_selected, aes(x = tempo, fill = year, color = year)) +
  geom_histogram(binwidth = 10, position = "identity", alpha = 0.6) + 
  theme_gray() +
  geom_vline(data=meanTempo, aes(xintercept = mean.tempo, color= year), linetype="dashed", show.legend = F) +
  geom_text(aes(x = mean.tempo + 8, y = 50, label = round(mean.tempo, 2), color = year), data = meanTempo) +
  labs(
    title = "Histogram of Tempo Distribution",
    x = "Tempo",
    y = "Count"
  ) +
  scale_color_manual(values=c("#999999", "#E69F00")) +
  scale_fill_manual(values=c("#999999", "#E69F00"))

tempoPlot
```

***
This plot shows the tempo distribution of the tracks in the 1990's and the 2010's playlist. The '90s playlist shows a large peak in the lower BPM, while the '10s have a more equally distributed BPM. The vertical lines show the mean tempo. 

-- try to find a explanation for this! --

### Less rapping and more singing: How is the speechiness of the songs affected? {data-commentary-width=400}

```{r}
features %>% 
  plot_ly(x = ~year, y = ~speechiness, color = I("#E69F00"), hoverinfo = "text", text = ~paste("Song:", track.name, "<br>", "Artist(s):", artists.name), marker = list(color = "#999999")) %>%
  add_boxplot() %>% add_markers() %>% layout(showlegend = FALSE)
```

***
In the next plot the speechiness feature of both playlists is plotted. The songs from 2010 have less speechiness than the '90s. A possible cause of this could be the "popifying" of Hip-Hop and adding more singing to the tracks. 

-- add more detailed explanation! --

### Duration vs danceability vs acousticness {data-commentary-width=400}

```{r}
manyPlot <- ggplot(features, aes(x = danceability, y = duration_ms, size = acousticness, color = year)) + 
  geom_point(alpha = 0.6) +
  theme_gray() +
  scale_color_manual(values=c("#999999", "#E69F00")) +
  scale_fill_manual(values=c("#999999", "#E69F00"))

manyPlot
```

***
The last plot shows the duration of a song vs the danceability. The size of a point shows how high the acousticness is. The '90s songs seem to have a higher danceability than most '10s tracks. Except for a single outlier, most songs seem to have about the same duration. The acousticness does not seem to correlate to the duration or danceability. 

### Chromagram ;'( {data-commentary-width=400}
```{r}
grownManSport <-
  get_tidy_audio_analysis("7Ie9W94M7OjPoZVV216Xus") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

moment4Life <- 
  get_tidy_audio_analysis("1ia019RqDK2o4QiANR1Dyn") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

grownManSportChromagram <- grownManSport %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Grown Man Sport by Pete Rock") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) + 
  scale_fill_viridis_c()

moment4LifeChromagram <- moment4Life %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Moment 4 Life by Nicki Minaj") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_viridis_c()

figure <- ggarrange(grownManSportChromagram, moment4LifeChromagram, labels = c("1998", "2010"),
                    ncol = 2, nrow = 1, common.legend = TRUE, font.label = list(size = 10))

figure
```


***
Chromagram of two songs. I haven't really been able to find songs that have a really remarkable chromagram. I did want to see if I could show the chromagrams nicely, hence these two. 

### Dynamic Time Warping: When a song is sampled {data-commentary-width=400}
```{r}
## Mac Miller
macMiller <-
  get_tidy_audio_analysis("3VmrLy4WZLHDgTXENCIz2p") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
## Lord Finesse
lordFinesse <-
  get_tidy_audio_analysis("30eW6IlBK3wCwcB8TsPXua") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

compmus_long_distance(
  macMiller %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  lordFinesse %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  feature = pitches,
  method = "euclidean"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "Mac Miller", y = "Lord Finesse", title = "Similarity matrix between the original and sampled song") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_viridis_c(guide = NULL)
```

***
The 1996 song [Hip 2 Da Game by Lord Finesse](https://open.spotify.com/track/30eW6IlBK3wCwcB8TsPXua?si=2a7b96a1d9384f3f) is sampled by Mac Miller in his 2010 song called [Kool Aid and Frozen Pizza](https://open.spotify.com/track/3VmrLy4WZLHDgTXENCIz2p?si=c174207c0d68423f). Even though the background track is the same, the chromagram does not show this similarity. I suspect that the duration of the two songs have something to do with this. The Mac Miller version is about two minutes shorter than the Lord Finesse version. When dynamic time warping is performed, the Mac Miller song will need to be stretched quite a lot. 

### There seems to be an increase in structure in the Hip-Hop genre
```{r}
bigPoppa <-
  get_tidy_audio_analysis("2g8HN35AnVGIk7B8yMucww") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

bigPoppaPlot <- compmus_long_distance(
  bigPoppa %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  bigPoppa %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  feature = pitches,
  method = "euclidean"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "", y = "", title = "Big Poppa by The Notorious B.I.G.") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_viridis_c(guide = NULL)

antidote <-
  get_tidy_audio_analysis("1wHZx0LgzFHyeIZkUydNXq") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

antidotePlot <- compmus_long_distance(
  antidote %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  antidote %>% mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  feature = pitches,
  method = "euclidean"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "", y = "", title = "Antidote by Travis Scott") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_viridis_c(guide = NULL)

figure <- ggarrange(bigPoppaPlot, antidotePlot, labels = c("1994", "2015"),
                    ncol = 2, nrow = 1, font.label = list(size = 10))

annotate_figure(figure, top = text_grob("Self-similarity matrices", 
               color = "black", size = 14))
```

***
The difference between self-similarity matrices from the '90s and '10s is very apparent. In the song Big Poppa, a '90s classic, there are small bits of repetition, what one might call a small chorus. The beat is constant throughout the song and Biggie can be heard rapping the whole song. In the matrix of Antidote we see a very different pattern. The song has a lot of repetition, which is reflected in the vertical and horizontal stripes in the matrix. Travis Scott also raps less and he has picked up a more singing style than rapping. 

These matrices very well show the shift from the more rap and beat based '90s songs to the more popified way of making Hip-Hop (having the standard verse/chorus/bridge layout). 

### Conclusion :)
'90s hip-hop is gewoon beter, ik ben een simpel mens